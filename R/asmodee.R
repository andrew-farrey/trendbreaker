#' Automatic Selection of Models Outlier DEtection for Epidemics (ASMODEE)
#'
#' This function implements an algorithm for epidemic time series analysis in
#' aim to detect recent deviation from the trend followed by the data. Data is
#' first partitioned into 'recent' data, using the last `k` observations as
#' supplementary individuals, and older data used to fit the
#' trend. Trend-fitting is done by fitting a series of user-specified models for
#' the time series, with different methods for selecting best fit (see details,
#' and the argument `method`). The prediction interval is then calculated for
#' the best model, and every data point (including the training set and
#' supplementary individuals) falling outside are classified as 'outliers'. The
#' value of `k` can be fixed by the user, or automatically selected to minimise
#' outliers in the training period and maximise and the detection of outliers in
#' the recent period.
#'
#' @details Automatic model selection is used to determine the model best
#'   fitting the training data from a list of user-provided models. First, all
#'   models are fitted to the data. Second, models are selected using the
#'   approach specified by the `method` argument. The default,
#'   [`evaluate_resampling`](evaluate_resampling), uses cross-validation
#'   (10-fold by default) and root mean squared error (RMSE) to assess model
#'   fit. This approach is likely to select models with good predictive
#'   abilities, but is computationally intensive. The alternative is using
#'   [`evaluate_aic`](evaluate_aic), which uses Akaike's Information Criteria to
#'   assess model fit penalised by model complexity. This approach is fast, but
#'   only measures model fit rather than predictive ability.
#'
#' @author Thibaut Jombart, Dirk Schumacher and Tim Taylor, with inputs from
#'   Michael Höhle, Mark Jit, John Edmunds, Andre Charlett, Stéphane Ghozzi
#'
#' @export
#'
#' @rdname asmodee
#'
#' @param data A `data.frame` or a `tibble` containing the response and
#'   explanatory variables used in the `models`.
#'
#' @param models A list of [`trending_model()`] objects,
#'   generated by `lm_model`, `glm_model`, `glm_nb_model`, `brms_model` and
#'   similar functions (see `?trending::trending_model()`) for details.
#'
#' @param ... Further arguments passed to `method`.
#'
#' @return An `trendbreaker` object (S3 class inheriting `list`), containing items
#'   which can be accessed by various accessors - see `?trendbreaker-accessors`
#'
#' @examples
#'
#' if (require(cowplot) && require(tidyverse) && require(trending)) {
#'   ## load data
#'   data(nhs_pathways_covid19)
#'
#'   ## select last 28 days
#'   first_date <- max(nhs_pathways_covid19$date, na.rm = TRUE) - 28
#'   pathways_recent <- nhs_pathways_covid19 %>%
#'     filter(date >= first_date)
#'
#'   ## define candidate models
#'   models <- list(
#'     regression = lm_model(count ~ day),
#'     poisson_constant = glm_model(count ~ 1, family = "poisson"),
#'     negbin_time = glm_nb_model(count ~ day),
#'     negbin_time_weekday = glm_nb_model(count ~ day + weekday)
#'   )
#'
#'   ## analyses on all data
#'   counts_overall <- pathways_recent %>%
#'     group_by(date, day, weekday) %>%
#'     summarise(count = sum(count))
#'
#'   ## results with automated detection of 'k'
#'   res_overall <- asmodee(counts_overall,
#'                          models,
#'                          "date",
#'                          method = evaluate_aic)
#'   res_overall
#'   plot(res_overall, "date")
#'
#'   ## results with fixed value of 'k' (7 days)
#'   res_overall_k7 <- asmodee(counts_overall, models, date, fixed_k = 7)
#'   plot(res_overall_k7, "date")
#'
#' }
#'
asmodee <- function(data, models, ...) {
  UseMethod("asmodee", data)
}






#' @export
#'
#' @rdname asmodee
#'
#' @param date_index The name of a variable corresponding to time, quoted or
#'   not.
#'
#' @param alpha The alpha threshold to be used for the prediction interval
#'   calculation; defaults to 0.05, i.e. 95% prediction intervals are
#'   calculated.
#'
#' @param max_k An `integer` indicating the maximum number of recent data points
#'   to be excluded from the trend fitting procedure. By default, ASMODEE will
#'   look for a changepoint within this recent time period, after which data no
#'   longer fit the previous trend. Larger values will require more computation
#'   from the method. Only used if `fixed_k` is `NULL`.
#'
#' @param fixed_k An optional `integer` indicating the number of recent data
#'   points to be excluded from the trend fitting procedure. Defaults to `NULL`,
#'   in which case ASMODEE detects `k` automatically, at the expense of
#'   computational time.
#'
#' @param method A function used to evaluate model fit. Current choices are
#'   `evaluate_aic` (default) and `evaluate_resampling`. `evaluate_aic` uses
#'   Akaike's Information Criterion instead, which is faster but possibly less
#'   good a selecting models with the best predictive power.
#'   `evaluate_resampling` uses cross-validation and, by default, RMSE to assess
#'   model fit.
#'
#' @param simulate_pi Should the ciTools package be used to simulate prediction
#'   intervals for glm models. Defaults to TRUE.
#'
#' @param uncertain Only used for glm models. If FALSE uncertainty in the fitted
#'   parameters is ignored when generating the prediction intervals. Defaults to
#'   FALSE.
#'
#' @param include_warnings Include results in output that triggered warnings but
#'   not errors. Defaults to `FALSE`.
#'
#' @param force_positive A `logical` indicating if prediction should be forced
#'   to be positive (or zero); can be useful when using Gaussian models for
#'   count data, to censore confidence or prediction intervals and avoid
#'   negative predictions. Defaults to `FALSE` for general `data.frame` inputs,
#'   and to `TRUE` for `incidence2` objects.
#'
#' @param quiet A `logical` indicating if warnings and messages should be
#'   suppressed (TRUE) or use (FALSE, default).
#'
asmodee.data.frame <- function(data,
                               models,
                               date_index,
                               alpha = 0.05,
                               max_k = 7,
                               fixed_k = NULL,
                               method = trendeval::evaluate_aic,
                               simulate_pi = TRUE,
                               uncertain = FALSE,
                               include_warnings = FALSE,
                               quiet = FALSE,
                               force_positive = FALSE,
                               ...) {

  if (!length(models)) {
    msg <- "models has a length of zero"
    stop(msg)
  }
  
  ## As the method relies on a 'time' variable for defining training/testing
  ## sets, we first need to retrieve this information from the 'time_index'
  ## argument. We borrow the same strategy as the one used in the *incidence2*
  ## package. The rest of the algorithm will basically rely on:
  ##
  ##  1. defining the training by removing data of the most recent 'k' time
  ##  units in date_index; this is externalised in get_training_data()
  ##  2. performing automated model selection using the training set
  ##  3. deriving prediction intervals and classifying outliers

  date_index <- rlang::enquo(date_index)
  idx <- tidyselect::eval_select(date_index, data)
  date_index <- names(data)[idx]
  dates <- data[[date_index]]

  ## There are two modes for this function:
  ## 1. (default) auto-detection of the value of 'k', in which case we use the
  ## `detect_changepoint` routine to select the 'best' value of `k`
  ## 2. use a user-specified value of `k`, passed through the `fixed_k` argument

  if (is.null(fixed_k)) {
    res_changepoint <- detect_changepoint(
      data = data,
      models = models,
      date_index = date_index,
      alpha = alpha,
      max_k = max_k,
      method = method,
      include_warnings = include_warnings,
      ...
    )
    selected_model <- res_changepoint$model
    selected_k <- res_changepoint$k
  } else {
    if (!is.numeric(fixed_k) |
          !is.finite(fixed_k)) {
      msg <- "`fixed_k` must be a finite number"
      stop(msg)
    }
    
    selected_k <- as.integer(max(fixed_k, 0L))
    data_train <- get_training_data(data, date_index, selected_k)

    ## Here we need to eliminate models which would error when using predict on
    ## the testing set; this can be due to new levels in the prediction set for
    ## categorical predictors (factors), or to the presence of NAs in the
    ## predictors.
    models <- retain_sanitized_models(models,
                                      data_train,
                                      data,
                                      warn = !quiet,
                                      error_if_void = TRUE)
    selected_model <- select_model(data_train, models, method, include_warnings, ...)
    selected_model <- trending::fit(selected_model, data_train)
  }

  ## keep track of which data are training / testing and boundary dates
  data <- set_training_data(data, date_index, selected_k)
  training <- data$training
  last_training_date <- max(dates[training], na.rm = TRUE)
  first_testing_date <- NULL
  if (selected_k > 0) {
    first_testing_date <- min(dates[!training], na.rm = TRUE)
  }


  ## find outliers
  res_outliers <- detect_outliers(data = data,
                                  model = selected_model,
                                  alpha = alpha,
                                  simulate_pi = simulate_pi,
                                  uncertain = uncertain)

  ## enforce positive predictions if required
  neg_to_zero <- function(x) {
    x[x < 0] <- 0
    x
  }    
  if (force_positive) {
    res_outliers$estimate <- neg_to_zero(res_outliers$estimate)
    res_outliers$lower_ci <- neg_to_zero(res_outliers$lower_ci)
    res_outliers$upper_ci <- neg_to_zero(res_outliers$upper_ci)
    res_outliers$lower_pi <- neg_to_zero(res_outliers$lower_pi)
    res_outliers$upper_pi <- neg_to_zero(res_outliers$upper_pi)
  }

  ## final output
  out <- list(
    k = selected_k,
    model = selected_model,
    alpha = alpha,
    results = res_outliers,
    date_index = date_index,
    last_training_date = last_training_date,
    first_testing_date = first_testing_date
  )
  class(out) <- c("trendbreaker", class(out))
  out
}





#' @export
#'
#' @rdname asmodee
asmodee.incidence2 <- function(data,
                               models,
                               alpha = 0.05,
                               max_k = 7,
                               fixed_k = NULL,
                               method = trendeval::evaluate_aic,
                               simulate_pi = TRUE,
                               uncertain = FALSE,
                               include_warnings = FALSE,
                               force_positive = TRUE,
                               ...) {
  # check incidence2 package is present
  check_suggests("incidence2")

  groups <- incidence2::get_group_names(data)
  if (!is.null(groups)) {
    f_groups <- lapply(suppressMessages(data[groups]), factor, exclude = NULL)
    split_dat <- split(data, f_groups, sep = "-")
  } else {
    split_dat <- list(data)
  }
  date_index <- incidence2::get_dates_name(data)

  out <- lapply(split_dat,
                asmodee.data.frame,
                models = models,
                date_index = date_index,
                method = method,
                alpha = alpha,
                max_k = max_k,
                fixed_k = fixed_k,
                include_warnings = include_warnings,
                simulate_pi = simulate_pi,
                uncertain = uncertain,
                force_positive = force_positive,
                ...)

  names(out) <- names(split_dat)
  class(out) <- "trendbreaker_incidence2"
  out
}

is_ok <- function(x, include_warnings = FALSE) {
  e <- suppressMessages(
    vapply(x[["error"]], function(y) !is.null(y), logical(1))
  )

  idx <- !names(x) == "error"
  x <- x[!e, idx]


  if (!include_warnings) {
    w <- suppressMessages(
      vapply(x[["warning"]], function(y) !is.null(y), logical(1))
    )

    idx <- !names(x) == "warning"
    x <- x[!w, idx]
  }
  x
}
